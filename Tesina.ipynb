{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIBvM2S_xIji"
      },
      "source": [
        "# Dataset - Breast Cancer Wisconsin (Diagnostic)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvYZQ40bytvS"
      },
      "source": [
        "#import the libraries \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8lWKiqSq2fp"
      },
      "source": [
        "#1.View the dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0I_szLMzBeY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "5ba51477-b5cc-443f-fc9e-39358fee95d1"
      },
      "source": [
        "#load the breast cancer dataset \n",
        "\n",
        "breast_cancer=load_breast_cancer()\n",
        "\n",
        "#View the dataset \n",
        "attributes = np.array(breast_cancer.feature_names)\n",
        "X = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "y = pd.DataFrame(breast_cancer.target)\n",
        "df_breast_cancer = pd.DataFrame(breast_cancer.data,columns=breast_cancer.feature_names)\n",
        "df_breast_cancer['target'] = pd.Series(breast_cancer.target)\n",
        "df_breast_cancer.head(569)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890       0\n",
              "1          20.57         17.77  ...                  0.08902       0\n",
              "2          19.69         21.25  ...                  0.08758       0\n",
              "3          11.42         20.38  ...                  0.17300       0\n",
              "4          20.29         14.34  ...                  0.07678       0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115       0\n",
              "565        20.13         28.25  ...                  0.06637       0\n",
              "566        16.60         28.08  ...                  0.07820       0\n",
              "567        20.60         29.33  ...                  0.12400       0\n",
              "568         7.76         24.54  ...                  0.07039       1\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eEdfcxfSb41"
      },
      "source": [
        "# Distribution of class \n",
        "sns.set(style='darkgrid')\n",
        "ax = sns.countplot(x=\"target\", data=breast_cancer,order = df_breast_cancer['target'].value_counts().index)\n",
        "plt.show()\n",
        "n=df_breast_cancer['target'].value_counts()\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk0Ty2TPSf5L"
      },
      "source": [
        "#Check for missing values \n",
        "print(df_breast_cancer.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwmkc0FLKSh7"
      },
      "source": [
        "# 2.Data Visualization \n",
        "\n",
        "a. Histogram Plot \n",
        "\n",
        "b. Correlation  matrix \n",
        "\n",
        "c. Box Plot\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkMIkZP23hV1"
      },
      "source": [
        "#Histogram\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))  \n",
        "sns.histplot(data=df_breast_cancer, x=\"mean radius\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean texture\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean perimeter\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean area\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean smoothness\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean compactness\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean concavity\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean concave points\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean symmetry\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"mean fractal dimension\" ,hue=\"target\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "sns.histplot(data=df_breast_cancer, x=\" radius error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"texture error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"perimeter error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"area error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"smoothness error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"compactness error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"concavity error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"concave points error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"symmetry error\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"fractal dimension error\" ,hue=\"target\")\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst radius\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst texture\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst perimeter\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst area\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst smoothness\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst compactness\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst concavity\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst concave points\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst symmetry\" ,hue=\"target\")\n",
        "sns.histplot(data=df_breast_cancer, x=\"worst fractal dimension\" ,hue=\"target\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnWKJfOdTWLr"
      },
      "source": [
        "# Compute the correlation matrix\n",
        "sns.set_theme(style=\"white\")\n",
        "\n",
        "corr = X.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf4ZVu1oTg2b"
      },
      "source": [
        "#Box Plot mean group diagonis of tumor for M and B \n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "plot = sns.boxplot(x='target', y='mean texture', data=df_breast_cancer, showfliers=False)\n",
        "plt.title('Mean texture vs Diagonis of tumor')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'mean radius', data =df_breast_cancer )\n",
        "plt.title(' Mean radius vs Diagonis of tumor ')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'mean perimeter', data =df_breast_cancer )\n",
        "plt.title(' Mean perimeter vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'mean compactness', data =df_breast_cancer )\n",
        "plt.title(' Mean compactness vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'mean concavity', data =df_breast_cancer )\n",
        "plt.title(' Mean concavity vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'mean concave points', data =df_breast_cancer )\n",
        "plt.title(' Mean concave points vs Diagonis of tumor ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klWVpJ2_Ca4J"
      },
      "source": [
        "#Box Plot error group diagonis of tumor for M and B\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "plot = sns.boxplot(x='target', y='texture error', data=df_breast_cancer, showfliers=False)\n",
        "plt.title('Error texture vs Diagonis of tumor')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'radius error', data =df_breast_cancer )\n",
        "plt.title('Error radius vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'perimeter error', data =df_breast_cancer )\n",
        "plt.title('Error perimeter vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'compactness error', data =df_breast_cancer )\n",
        "plt.title('Error compactness vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'concavity error', data =df_breast_cancer )\n",
        "plt.title(' Error concavity vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'concave points error', data =df_breast_cancer )\n",
        "plt.title(' Error concave vs Diagonis of tumor ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km2MnAjXD7nk"
      },
      "source": [
        "#Box Plot worst group diagonis of tumor for M and B\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "plot = sns.boxplot(x='target', y='worst texture', data=df_breast_cancer, showfliers=False)\n",
        "plt.title('Worst texture vs Diagonis of tumor')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'worst radius', data =df_breast_cancer )\n",
        "plt.title('Worst radius vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'worst perimeter', data =df_breast_cancer )\n",
        "plt.title('Worst perimeter error vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'worst compactness', data =df_breast_cancer )\n",
        "plt.title('Worst compactness error vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'worst concavity', data =df_breast_cancer )\n",
        "plt.title(' Worst concavity vs Diagonis of tumor ')\n",
        "\n",
        "fig = plt.figure(figsize = (2,2))\n",
        "sns.boxplot(x = 'target', y = 'worst concave points', data =df_breast_cancer )\n",
        "plt.title(' Worst concave vs Diagonis of tumor ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-_RxFMITxgX"
      },
      "source": [
        "#3.Principal Component Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gILZs2fsfpib"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "standardized = StandardScaler()\n",
        "standardized.fit(df_breast_cancer)\n",
        "scaled_data = standardized.transform(df_breast_cancer)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "dfx_pca=pca.fit(scaled_data)\n",
        "x_pca = pca.transform(scaled_data)\n",
        "\n",
        "print(\"Variance explained by all the 2 components =\" , sum(pca.explained_variance_ratio_ * 100))\n",
        "\n",
        "\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Explained variance')\n",
        "plt.savefig('elbow_plot.png', dpi=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1HFfht4h2Da"
      },
      "source": [
        "#Print the variances \n",
        "print(\"Variance explained by the First principal component=\", np.cumsum(pca.explained_variance_ratio_*100)[0])\n",
        "print(\"Variance explained by the Second principal component=\", np.cumsum(pca.explained_variance_ratio_*100)[1])\n",
        "print(\"Variance explained by the Third principal component=\", np.cumsum(pca.explained_variance_ratio_*100)[2])\n",
        "print(\"Variance explained by the First 10 principal component=\", np.cumsum(pca.explained_variance_ratio_*100)[9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxRF5WDi1RB"
      },
      "source": [
        "# PCA =2 Components \n",
        "pca= PCA(n_components=2)\n",
        "dfx_pca=pca.fit(scaled_data)\n",
        "x_pca = pca.transform(scaled_data)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.scatterplot(x=x_pca[:,0], y=x_pca[:,1],s=70, hue=breast_cancer.target, palette=['orange','red'])\n",
        "plt.title(\"2D Scatterplot: 63.36% of the variability captured\", pad=15)\n",
        "plt.xlabel(\"First principal component\")\n",
        "plt.ylabel(\"Second principal component\")\n",
        "plt.savefig(\"2d_scatterplot.png\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHLAJMP9lwco"
      },
      "source": [
        "# PCA = 3 Components \n",
        "\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "pca= PCA(n_components=3)\n",
        "dfx_pca=pca.fit(scaled_data)\n",
        "x_pca = pca.transform(scaled_data)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "ax=plt.axes(projection='3d')\n",
        "\n",
        "sctt=ax.scatter3D(x_pca[:,0], x_pca[:,1], x_pca[:,2],c=breast_cancer.target,s=50,alpha=0.6)\n",
        "\n",
        "plt.title(\"3D Scatterplot: 72.55% of the variability captured\", pad=15)\n",
        "ax.set_xlabel(\"First principal component\")\n",
        "ax.set_ylabel(\"Second principal component\")\n",
        "ax.set_zlabel(\"Third principal component\")\n",
        "\n",
        "plt.savefig(\"2d_scatterplot.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVv6Vt3rMFG5"
      },
      "source": [
        "#Explained Variance Ratio\n",
        "standardized = StandardScaler()\n",
        "standardized.fit(df_breast_cancer)\n",
        "scaled_data = standardized.transform(df_breast_cancer)\n",
        "\n",
        "pca = PCA(n_components=10)\n",
        "dfx_pca=pca.fit(scaled_data)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(x=[i+1 for i in range(len(dfx_pca.explained_variance_ratio_))],\n",
        "            y=dfx_pca.explained_variance_ratio_,\n",
        "           s=200, alpha=0.75,c='orange',edgecolor='k')\n",
        "plt.grid(True)\n",
        "plt.title(\"Explained variance ratio of the \\nfitted principal component vector\\n\",fontsize=25)\n",
        "plt.xlabel(\"Principal components\",fontsize=15)\n",
        "plt.xticks([i+1 for i in range(len(dfx_pca.explained_variance_ratio_))],fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.ylabel(\"Explained variance ratio\",fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N_wCqcpt2tX"
      },
      "source": [
        "#4.Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w4SXiVs9B6A"
      },
      "source": [
        "# randomly splitting the data (5:2:3) in train , val, test \n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, random_state = 42,stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, train_size = 5/7, shuffle = True, random_state = 42)\n",
        "print (' Training and validation:' +repr(len(X_train_val)))\n",
        "print (' Training:' +repr(len(X_train)))\n",
        "print (' Validation:' +repr(len(X_val)))\n",
        "print (' Test:' +repr(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXeu1YPJprxN"
      },
      "source": [
        "# MinMax Scaling  \n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train_val=scaler.fit_transform(X_train_val)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Z1pdJxAsoZ"
      },
      "source": [
        "#5.K-Nearest-Neighbors \n",
        "\n",
        "K-NN classification using different values of K."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfeDWkp69pxW"
      },
      "source": [
        "#Create the model \n",
        "k_values = [1,3,5,7,9]\n",
        "acc_scores = []\n",
        "\n",
        "# trying with different values of K \n",
        "for K in k_values:\n",
        "    model1 = KNeighborsClassifier(n_neighbors = K , p=2)\n",
        "    model1.fit(X_train, y_train)\n",
        "  \n",
        "    y_pred = model1.predict(X_train_val)\n",
        "    \n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model1.score(X_train, y_train) *100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcY7UXWd9-zF"
      },
      "source": [
        "#cross validation to select the best value of K \n",
        "neighbors = [] \n",
        "cv_scores = [] \n",
        "  \n",
        "from sklearn.model_selection import cross_val_score \n",
        "# perform 5 fold cross validation \n",
        "for k in range(1, 11, 2): \n",
        "    neighbors.append(k) \n",
        "    knn = KNeighborsClassifier(n_neighbors = k, p=2) \n",
        "    scores = cross_val_score( knn, X_train_val, y_train_val, cv = 5, scoring = 'accuracy') \n",
        "    cv_scores.append(scores.mean()) \n",
        "    \n",
        "MSE = [1-x for x in cv_scores] \n",
        "  \n",
        "# determining the best k \n",
        "optimal_k = neighbors[MSE.index(min(MSE))] \n",
        "print('The optimal number of neighbors is % d ' % optimal_k) \n",
        "  \n",
        "# plot misclassification error versus k \n",
        "plt.figure(figsize = (6, 4)) \n",
        "plt.plot(neighbors, MSE) \n",
        "plt.xlabel('Number of neighbors') \n",
        "plt.ylabel('Misclassification Error') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZcDWTJS55Jo"
      },
      "source": [
        "#create a new KNN model with best parameters\n",
        "model_best1 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
        "model_best1.fit(X_train_val, y_train_val)\n",
        "  \n",
        "y_pred = model_best1.predict(X_test)\n",
        "\n",
        "print(\"Test accuarcy :\", accuracy_score(y_test,y_pred)* 100)\n",
        "\n",
        "#Classification report\n",
        "cm = classification_report(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "#Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "#Plot of ROC Curve \n",
        "metrics.plot_roc_curve(model_best1, X_test, y_test)\n",
        "plt.show()  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikUkdyfzq_YT"
      },
      "source": [
        "#6.Linear and RBF SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uV_xPo-rYT7"
      },
      "source": [
        "# Create the model\n",
        "model2 =SVC(C=10, kernel='linear')\n",
        "\n",
        "# feeding the training data into the model\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# predicting the validation set results\n",
        "y_pred = model2.predict(X_train_val)\n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model2.score(X_train, y_train)*100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)\n",
        "print(\"Testing accuarcy :\", accuracy_score(y_test,y_pred)*100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHtK0xIt3y_B"
      },
      "source": [
        "# Create the model\n",
        "model2 =SVC(C=10, kernel='rbf',gamma=0.1)\n",
        "\n",
        "# feeding the training data into the model\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# predicting the validation set results\n",
        "y_pred = model2.predict(X_train_val)\n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model2.score(X_train, y_train)*100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KyeQf9vr5Z1"
      },
      "source": [
        "# using grid search to find the best parameters for svm\n",
        "\n",
        "param = {\n",
        "    'C': [0.8,0.9,1,1.1,1.2,1.3,1.4,10],\n",
        "    'kernel':['linear', 'rbf'],\n",
        "    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
        "}\n",
        "grid_svc = GridSearchCV(model2, param_grid = param, scoring = 'accuracy', cv = 10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqXvrt-r_GZ"
      },
      "source": [
        "grid_svc.fit(X_train_val, y_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QymqS6Q8sFp7",
        "outputId": "8c1f9921-e797-4bf7-b47f-fcd4cbb0cc8f"
      },
      "source": [
        "grid_svc.best_params_"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.8, 'gamma': 0.1, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOZ5e3rUsGzT"
      },
      "source": [
        "# creating a new SVC model with these best parameters\n",
        "model_best2 = SVC(C = 0.8, gamma = 0.1, kernel = 'linear')\n",
        "model_best2.fit(X_train_val, y_train_val)\n",
        "y_pred = model_best2.predict(X_test)\n",
        "\n",
        "#Test Accuracy \n",
        "print(\"Testing accuarcy :\", accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "#Classification Report \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "#Plot of ROC Curve \n",
        "metrics.plot_roc_curve(model_best2, X_test, y_test)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCGHonMEuhf2"
      },
      "source": [
        "#7.Logistic Regression \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnkxlYcuuOLs"
      },
      "source": [
        "# creating the model\n",
        "model3 = LogisticRegression(random_state = 0)\n",
        "\n",
        "# feeding the training data into the model\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# predicting the validation set results\n",
        "y_pred = model3.predict(X_train_val)\n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model3.score(X_train, y_train)*100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIdd55zuOCD"
      },
      "source": [
        "# using grid search to find the best parameters for LR\n",
        "\n",
        "param = {\n",
        "    'C': [0.001, 0.1, 1, 10, 100]\n",
        "}\n",
        "grid_LR = GridSearchCV(model3, param_grid = param, scoring = 'accuracy', cv = 10)\n",
        "\n",
        "grid_LR.fit(X_train_val, y_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6qO6zBsup9M",
        "outputId": "fb84399d-1ded-4007-b9a3-9d82f11e714f"
      },
      "source": [
        "grid_LR.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyylqAX-N9xt"
      },
      "source": [
        "# creating a new LR model with these best parameter C\n",
        "best_model3= LogisticRegression(C=10)\n",
        "best_model3.fit(X_train_val, y_train_val)\n",
        "y_pred = best_model3.predict(X_test)\n",
        "print(\"Testing accuarcy :\", accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "# classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)\n",
        "\n",
        "# Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "#Plot of ROC Curve \n",
        "metrics.plot_roc_curve(best_model3, X_test, y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB9TmuwVswxP"
      },
      "source": [
        "#8.Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsfItqZGsi1q"
      },
      "source": [
        "# Creating a model\n",
        "model4 = DecisionTreeClassifier()\n",
        "\n",
        "# feeding the training set into the model\n",
        "model4.fit(X_train, y_train)\n",
        "\n",
        "# predicting the validation set results\n",
        "y_pred = model4.predict(X_train_val)\n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model4.score(X_train, y_train)*100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTn-0xAQxeUf"
      },
      "source": [
        "# using grid search to find the best parameters for Decision Tree\n",
        "\n",
        "param = {\n",
        "    'criterion':['entropy', 'gini'],\n",
        "    'max_depth':[10, 50, 100]\n",
        "}\n",
        "grid_DT = GridSearchCV(model4, param_grid = param, scoring = 'accuracy', cv = 10)\n",
        "\n",
        "grid_DT.fit(X_train_val, y_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY5P-Hjux9ih",
        "outputId": "d19ed939-8a1e-4631-a1d8-06d81101563b"
      },
      "source": [
        "grid_DT.best_params_"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_depth': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFqK-t77Eeet"
      },
      "source": [
        "#creating a new Decison Tree model with these best parameters\n",
        "\n",
        "best_model4= DecisionTreeClassifier(criterion ='entropy', max_depth =100 ,random_state=0)\n",
        "best_model4.fit(X_train_val, y_train_val)\n",
        "y_pred = best_model4.predict(X_test)\n",
        "print(\"Testing accuarcy :\", accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "# classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)\n",
        "\n",
        "# Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "#Plot of ROC Curve \n",
        "metrics.plot_roc_curve(best_model4, X_test, y_test)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WgJdQAHGKc5"
      },
      "source": [
        "#Visualizing the decison Tree\n",
        "import graphviz\n",
        "fig = plt.figure(figsize=(25,15)) \n",
        "tree.plot_tree(best_model4, feature_names=breast_cancer.feature_names,class_names=breast_cancer.target_names,filled=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wNUZ7sktAxG"
      },
      "source": [
        "#9.Random Forest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urCdbXT0s_v2"
      },
      "source": [
        "# creating a model\n",
        "model5 = RandomForestClassifier()\n",
        "\n",
        "# feeding the training set into the model\n",
        "model5.fit(X_train, y_train)\n",
        "\n",
        "# predicting the validation set results\n",
        "y_pred = model5.predict(X_train_val)\n",
        "\n",
        "# Calculating the accuracies\n",
        "print(\"Training accuracy :\", model5.score(X_train, y_train)*100)\n",
        "print(\"Validation accuarcy :\", accuracy_score(y_train_val,y_pred)*100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoysBqNJ0CAr"
      },
      "source": [
        "param = {\"n_estimators\": np.arange(10,100,5),\n",
        "              \"min_samples_split\": np.arange(2,100,2),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]\n",
        "               \"max_depth\" :np.arange(10,100,10)\n",
        "                \max_features\":['auto', 'sqrt']\n",
        "                \bootstrap\":[True,False]
        "              }\n",
        "grid_RF = RandomizedSearchCV(model5, param_distributions = param, scoring = 'accuracy', cv = 10)\n",
        "grid_RF.fit(X_train_val, y_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ1sHWgu2KOh",
        "outputId": "85f45de7-d676-4fb7-e346-5e2ca51fe14a"
      },
      "source": [
        "grid_RF.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,'criterion': 'entropy','max_depth': 30,'max_features': 'auto','min_samples_split': 8,'n_estimators': 65}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxMGbTJpGAQC"
      },
      "source": [
        "best_model5= RandomForestClassifier(bootstrap='True',criterion ='entropy', max_depth=30,max_features='auto',min_samples_split =8,n_estimators= 65,random_state=20)\n",
        "best_model5.fit(X_train_val, y_train_val)\n",
        "y_pred = best_model5.predict(X_test)\n",
        "print(\"Testing accuarcy :\",accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "# classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(cr)\n",
        "\n",
        "# Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')\n",
        "\n",
        "#Plot of ROC Curve \n",
        "metrics.plot_roc_curve(best_model5, X_test, y_test)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
